{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:51:58.991630900Z",
     "start_time": "2023-07-28T01:51:58.215668800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from jddb.file_repo import FileRepo\n",
    "from jddb.processor import ShotSet\n",
    "from util.basic_processor import SliceProcessor, FFTProcessor, find_tags, AlarmTag, get_machine_tags\n",
    "from jddb.processor.basic_processors import ResamplingProcessor,TrimProcessor\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and feature extraction\n",
    "\n",
    "This notebook demonstrates how to access the provided data -3 file repo for 3 machines- with JDDB library. \n",
    "\n",
    "It show how 3 machines may have different names for the same -equivalent- diagnostics, and how to use the `ITU data - -signal.csv` to find common names for them.\n",
    "\n",
    "It also shows how to use JDDB processors to extract new features like dominant frequency.\n",
    "\n",
    "It also shows how to use JDDB processors to down sample the signals and clip only useful part of the signals and trim them to the same length.\n",
    "\n",
    "The output of this notebook is a Filerepo -same format as the provided data- of the processed data.\n",
    "\n",
    "You do not have to follow this routine, and you can process the data the way you like. This just gives you same examples of how to read the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose common signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read signal csv file\n",
    "\n",
    "this file have signal names for 3 machines, the same row means the same -equivalent- diagnostics.\n",
    "\n",
    "if the machine lacks some diagnostics, it will be left blank.\n",
    "\n",
    "The left most column is the common names for the diagnostics from 3 machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:51:59.009571Z",
     "start_time": "2023-07-28T01:51:58.989639500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_signal = pd.read_csv('ITU data - signal.csv') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Choose only signals that presented in all 3 machines\n",
    "\n",
    " check every signal, if it isn't empty in all 3 machine signal list, it should be included in common_signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.255022300Z",
     "start_time": "2023-07-28T01:51:59.012560900Z"
    }
   },
   "outputs": [],
   "source": [
    "common_signal = []\n",
    "for signal_name in df_signal.Diagnostics:\n",
    "    target_row = df_signal.loc[df_signal.Diagnostics == signal_name]\n",
    "    if ~target_row['J-TEXT MDSplus Tag'].isna().values[0] and \\\n",
    "            ~target_row['C-Mod MDSplus Tag'].isna().values[0]:\n",
    "        common_signal.append(signal_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change common_signal to different sub list according to whether it belongs to array mirnove, sxr, axuv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.255022300Z",
     "start_time": "2023-07-28T01:51:59.042468Z"
    }
   },
   "outputs": [],
   "source": [
    "# below 3 signals are array diagnostics signals, signals from same array can be treated the same way -feature extraction-\n",
    "mir_name_list = find_tags('poloidal', common_signal) + find_tags('toroidal Mir', common_signal)\n",
    "# sxr and axuv is not used in this example\n",
    "sxr_name_list = find_tags('soft', common_signal)\n",
    "axuv_name_list = find_tags('AXUV', common_signal)\n",
    "# the rest is not array signals they will be used as is, not feature extraction is needed\n",
    "basic_name_list = list(set(common_signal) - set(mir_name_list + sxr_name_list + axuv_name_list))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose machine for processing and get machine tags by common name list\n",
    "\n",
    "in this example model for 1 machines is to be built, so choose one machine and use its signal names to access its Filerepo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.257289500Z",
     "start_time": "2023-07-28T01:51:59.057946700Z"
    }
   },
   "outputs": [],
   "source": [
    "machine_name = 'J-TEXT'\n",
    "basic_machine_tags = get_machine_tags(machine_name, basic_name_list, df_signal)\n",
    "mir_machine_tags = get_machine_tags(machine_name, mir_name_list, df_signal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create file repos for processed data and select shots meets the requirement\n",
    "\n",
    "### initial the filerepo which should be processed and set the filerepo for training. these 2 filerepo should have different file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.257289500Z",
     "start_time": "2023-07-28T01:51:59.071899700Z"
    }
   },
   "outputs": [],
   "source": [
    "# this file repo is the provided original data -so extract the data into the \"data\" folder-\n",
    "source_file_repo = FileRepo('.//data//jtext//$shot_2$00//')\n",
    "# this is a new filerepo you created to hold the processed data\n",
    "train_file_repo = FileRepo('.//data//jtext_data_train//$shot_2$00//')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### create a valid shot set, the valid shots should contain target tags and enough flattop time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.257289500Z",
     "start_time": "2023-07-28T01:51:59.086849500Z"
    }
   },
   "outputs": [],
   "source": [
    "source_shotset = ShotSet(source_file_repo)\n",
    "shot_list = source_shotset.shot_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define the target tags which should be contained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.258012200Z",
     "start_time": "2023-07-28T01:51:59.101799900Z"
    }
   },
   "outputs": [],
   "source": [
    "targ_tags = basic_machine_tags + mir_machine_tags\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Get valid shot set\n",
    " Initialize an empty list to store valid shots.  \n",
    " Check if all target tags are present in the shot's tags and down_time of shot is greater than 0.2s -start time is ignored since they are all similar and matter little in this case-. \n",
    " Create a new ShotSet object using the valid shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.258012200Z",
     "start_time": "2023-07-28T01:51:59.137679400Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_shots = [] \n",
    "for shot in shot_list:\n",
    "    all_tags = list(source_shotset.get_shot(shot).tags)\n",
    "    last_time = list(source_file_repo.read_labels(shot, ['DownTime']).values())\n",
    "    \n",
    "    if all(tag in all_tags for tag in targ_tags) & (last_time[0] > 0.2):\n",
    "        valid_shots.append(shot)\n",
    "valid_shotset = ShotSet(source_file_repo, valid_shots) \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features and create training data\n",
    "\n",
    "### 1. FFT processing to extract dominant frequency and amplitude of mirnov signals\n",
    "\n",
    "Caution! this step will take very long if you have lots of data, and uses big amount of ram, may cause OOM exception.\n",
    "\n",
    "Steps:\n",
    "1. get mir signal tags of machine \n",
    "1. slicing, using slicing windows to create the data for FFT processing  -using JDDB processors-\n",
    "3. fft  to extract new features -using JDDB processors-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.258012200Z",
     "start_time": "2023-07-28T01:52:03.094581700Z"
    }
   },
   "outputs": [],
   "source": [
    "for signal_name in mir_name_list:\n",
    "    target_row = df_signal.loc[df_signal.Diagnostics == signal_name]\n",
    "    mir_tag = target_row['{} MDSplus Tag'.format(machine_name)].values[0]\n",
    "    processed_shotset = valid_shotset.process(\n",
    "        processor=SliceProcessor(window_length=250, overlap=0.9),\n",
    "        input_tags=[mir_tag],\n",
    "        output_tags=[\"sliced_MA_{}\".format(mir_tag)],\n",
    "        save_repo=train_file_repo)\n",
    "\n",
    "    processed_shotset = processed_shotset.process(\n",
    "        processor=FFTProcessor(),\n",
    "        input_tags=[\"sliced_MA_{}\".format(mir_tag)],\n",
    "        output_tags=[[\"fft_amp_{}\".format(mir_tag), \"fft_fre_{}\".format(mir_tag)]],\n",
    "        save_repo=train_file_repo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. remove redundant tags and keep tags for model training\n",
    "\n",
    "remove remove the sliced signals.\n",
    "\n",
    "extracted features and basics signals should be kept.\n",
    "  \n",
    "mir signals have been processed, they shouldn't be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.258012200Z",
     "start_time": "2023-07-28T01:52:52.620322700Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "shot_list = processed_shotset.shot_list\n",
    "all_tags = list(processed_shotset.get_shot(shot_list[0]).tags)\n",
    "fft_tag = find_tags('fft_', all_tags) \n",
    "keep_tags = basic_machine_tags + fft_tag  \n",
    "processed_shotset = processed_shotset.remove_signal(tags=keep_tags, keep=True,\n",
    "                                                    save_repo=train_file_repo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. resample high frequency tags\n",
    "\n",
    "down sample the signals to 1kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:54.258012200Z",
     "start_time": "2023-07-28T01:52:53.290362900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "down_tags = fft_tag\n",
    "processed_shotset = processed_shotset.process(\n",
    "    processor=ResamplingProcessor(1000),\n",
    "    input_tags=down_tags,\n",
    "    output_tags=down_tags,\n",
    "    save_repo=train_file_repo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. trim  signal\n",
    "change the machine tags to common names  \n",
    "keep common names\n",
    "\n",
    "so you can use common names in training, the training part will be machine agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:55.975882600Z",
     "start_time": "2023-07-28T01:52:54.255022300Z"
    }
   },
   "outputs": [],
   "source": [
    "common_tags = basic_name_list + fft_tag  \n",
    "processed_shotset = processed_shotset.process(\n",
    "    TrimProcessor(),\n",
    "    input_tags=[keep_tags],\n",
    "    output_tags=[common_tags],\n",
    "    save_repo=train_file_repo)\n",
    "keep_tags = basic_name_list + fft_tag  \n",
    "processed_shotset = processed_shotset.remove_signal(tags=keep_tags, keep=True,\n",
    "                                                    save_repo=train_file_repo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. add disruption labels for each time point as a signal called alarm_tag\n",
    "\n",
    "alarm tag is 0,1 labels for every time steps, 0 for non-disruption-precursor samples, 1 for disruption-precursor samples. all samples 'lead_time ' before disruptions is labeled 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T01:52:57.037797800Z",
     "start_time": "2023-07-28T01:52:55.976879Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_shotset = processed_shotset.process(\n",
    "    processor=AlarmTag(lead_time=0.1, disruption_label=\"IsDisrupt\", downtime_label=\"DownTime\"),\n",
    "    input_tags=[\"plasma current\"],\n",
    "    output_tags=[\"alarm_tag\"],\n",
    "    save_repo=train_file_repo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
